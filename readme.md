# ðŸš¨ Fraud Detection Using Machine Learning (XGBoost)

This project implements a **Machine Learning pipeline** to detect fraudulent financial transactions using **XGBoost**.  
It demonstrates an **end-to-end workflow** from data preprocessing to evaluation, with practical recommendations for fraud prevention.  

---

## ðŸ“‘ Table of Contents
- [ðŸ“Œ Project Overview](#-project-overview)  
- [ðŸ“‚ Dataset Description](#-dataset-description)  
- [âš™ï¸ Data Preprocessing](#ï¸-data-preprocessing)  
- [ðŸ” Feature Selection](#-feature-selection)  
- [ðŸ§  Model Building](#-model-building)  
- [ðŸ“Š Evaluation Metrics](#-evaluation-metrics)  
- [ðŸ’¡ Key Insights](#-key-insights)  
- [ðŸ›¡ Recommendations for Fraud Prevention](#-recommendations-for-fraud-prevention)  
- [ðŸ“ˆ Effectiveness Evaluation](#-effectiveness-evaluation)  
- [â–¶ï¸ How to Run](#ï¸-how-to-run)  
- [ðŸ“¦ Requirements](#-requirements)  
- [âœï¸ Author](#ï¸-author)  

---

## ðŸ“Œ Project Overview
The goal is to build a **fraud detection model** that identifies suspicious transactions in a financial dataset.  
- Special attention on **imbalanced data**.  
- Focused on **precision & recall**, as fraud detection is **rare but costly**.  

---

## ðŸ“‚ Dataset Description
**Fields:**  
`step, type, amount, oldbalanceOrg, newbalanceOrig, oldbalanceDest, newbalanceDest, isFraud, isFlaggedFraud`  

- **Dropped:** `nameOrig`, `nameDest` (identifiers)  
- **Target Column:** `isFraud` â†’ (1 = fraud, 0 = genuine)  
- **Class Distribution:** Highly imbalanced (~0.1% fraud)  

---

## âš™ï¸ Data Preprocessing
- âœ… No missing values  
- âœ… Outliers retained (possible fraud indicators)  
- âœ… Encoded categorical `type` using `LabelEncoder`  
- âœ… Standardized features using `StandardScaler`  
- âœ… Train-test split (80/20)  

---

## ðŸ” Feature Selection
**Features Used:**  
`step, type, amount, oldbalanceOrg, newbalanceOrig, oldbalanceDest, newbalanceDest, isFlaggedFraud`  

**Dropped:**  
`nameOrig, nameDest` (irrelevant)  

---

## ðŸ§  Model Building
- **Algorithm:** `XGBClassifier (XGBoost)`  
- Chosen for handling **imbalanced data & complex feature interactions**  
- Model trained & evaluated with multiple metrics  

---

## ðŸ“Š Evaluation Metrics
- **Accuracy:** ~99.8% âš ï¸ (misleading for imbalanced data)  
- **Precision (Fraud):** 25%  
- **Recall (Fraud):** 41%  
- **F1-Score (Fraud):** 31%  
- **Visuals:** Confusion Matrix, ROC, PR-Curve  

ðŸ‘‰ **Note:** Precision & Recall are more meaningful than accuracy here.  

---

## ðŸ’¡ Key Insights
- ðŸ”‘ Important features: **Transaction Type, Amount, Balance features**  
- ðŸš© Fraud concentrated in **large TRANSFER & CASH_OUT transactions**  
- ðŸ“‰ Model recall is decent but requires improvements for fewer false positives/negatives  

---

## ðŸ›¡ Recommendations for Fraud Prevention
- âš¡ **Real-time monitoring** of large/unusual transactions  
- â›” **Threshold rules** (block transactions where `amount > balance`)  
- ðŸ”‘ **Multi-Factor Authentication (MFA)** for large/first-time transfers  
- ðŸ“Š **Behavioral profiling** â†’ user spending patterns  
- ðŸ”„ **Continuous model retraining** with fresh data  
- ðŸ” **Secure, real-time analytics infrastructure**  

---

## ðŸ“ˆ Effectiveness Evaluation
- ðŸ“Š Track: fraud detection rate, false positives, financial loss  
- ðŸ§ª Use **A/B testing** for fraud prevention measures  
- ðŸ—£ Collect **customer feedback** on usability  
- ðŸ”„ Continuous **dashboard updates & retraining**  

---


## ðŸ“¦ Requirements
- Python >= 3.7  
- `numpy`, `pandas`, `matplotlib`, `seaborn`  
- `scikit-learn`, `xgboost`  

Install all dependencies via:  
```bash
pip install numpy pandas matplotlib seaborn scikit-learn xgboost
